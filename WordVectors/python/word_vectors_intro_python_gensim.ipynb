{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Vectors Intro (in python with `gensim`)\n",
    "---------\n",
    "\n",
    "Author: Felix Muzny  \n",
    "Date: 6/30/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Started & Using this notebook\n",
    "------\n",
    "\n",
    "This file is an introduction to training and querying a model using word2vec with `python` and `jupyter notebooks` on your own computer.\n",
    "\n",
    "For more information about how to use Jupyter Notebooks:\n",
    "- [An introduction to Jupyter Notebooks](https://realpython.com/jupyter-notebook-introduction/)\n",
    "- [Felix's Notes from an intro computer science course](https://muzny.github.io/csci1200-notes/01/using-jupyter-notebooks.html)\n",
    "\n",
    "A *very brief* intro to how to use this file/Jupyter Notebooks\n",
    "-----\n",
    "(See [section 1.1 of the Jupyter/Python notes](https://muzny.github.io/csci1200-notes/01/1/intro_jupyter_notebooks.html) for more detail)\n",
    "\n",
    "Jupyter notebooks are composed of `cell`s. A cell either contains text (like this one) or runnable python code.\n",
    "\n",
    "To run a cell with code in it, you'll either use one of the buttons at the top of the notebook (\"‚ñ∂Ô∏è Run\") or use a keyboard shortcut to run a cell (or cells). To view the keyboard shortcut for running cells, got to the \"Cell\" menu at the top of the notebook, then look at what is listed next to \"Run Cells\". By default, this is command+enter on mac operating systems and control+enter on windows.  \n",
    "\n",
    "When you run a cell that contains python code, two things happen:\n",
    "1. any output as a result of running the code is displayed beneath the cell\n",
    "2. any variables or functions defined as a result of running the code are stored in the kernel (\"python's working memory\"--this memory is only reset if you restart your notebook or use the Kernel menu to restart the kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example‚Äîrun this cell!\n",
    "favorite_animal = \"whale\"  # define a string variable\n",
    "favorite_number = 27  # define an integer variable\n",
    "print(favorite_animal)  # print out the value of one of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the variables that you defined in the previous cell are now defined \n",
    "# in our current memory so we can access them and do what we want with\n",
    "# them\n",
    "print(favorite_number)\n",
    "print(favorite_number ** 2)  # what is the value of this number squared?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last type of output that you might see underneath a cell is output that is preceded by the text `Out [n]:` (where `n` is some number). This output happens if no code in the cell displayed anything using `print` *and* the last line of code in the cell evaluates some expression that isn't saved in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of a cell with Out [n]: output\n",
    "# let's just do math and both not print it and not save it in a variable\n",
    "# notice that because we didn't save this value in a variable, we can't \n",
    "# access it later unless we re-do the calculation!\n",
    "favorite_number / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your notebook is ever running and you want to stop it, you can press the stop (\"üî≥\") button on the top menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing libraries \n",
    "----------------\n",
    "(in general and for this project)\n",
    "\n",
    "By default, python comes with some libraries already installed. Some of the libraries that we'll use (e.g. `gensim`) do not come installed by default. Depending on how you installed Jupyter Notebook, you'll follow different installation instructions. \n",
    "\n",
    "You'll likely be installing libraries via either:\n",
    "1. `conda`\n",
    "2. `conda` via the Anaconda Navigator user interface\n",
    "3. `pip`\n",
    "\n",
    "For help with this reach out to Felix (f.muzny@northeastern.edu) or the vast but sometimes confusing knowledge base of The Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access tools in a certain library, you'll need to import that library\n",
    "# in jupyter notebooks, we tend to like to put imports together without \n",
    "# other code in the cell to separate loading a library from code that \"does things\"\n",
    "import re  # for regular expressions\n",
    "import os  # to look up operating system-based info\n",
    "import string  # to do fancy things with strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, figure out what your working directory is\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're using a relative path to take your working directory, go \"back\"/\"up\" one\n",
    "# step to the maing WordVectors folder, then go into the data folder within that\n",
    "datapath = os.path.join(os.getcwd(), '..', 'data/WomensNovelsDemo/')\n",
    "print(\"Using datapath:\", datapath)\n",
    "# if this worked successfully, you should see a list of the files that \n",
    "# you are trying to work with here:\n",
    "print(\"We'll be working with the files:\")\n",
    "print(os.listdir(datapath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(list_of_texts):\n",
    "    '''\n",
    "    Cleans the given text using regular\n",
    "    expressions to split and lower-cased versions to create\n",
    "    a list of tokens for each text.\n",
    "    Parameters:\n",
    "        list_of_texts: list of str \n",
    "    Return: list of lists of tokens, one list per text\n",
    "    '''\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    all_tokens = []\n",
    "    for text in list_of_texts:\n",
    "        # lower case\n",
    "        tokens = text.split()\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "        # remove punctuation\n",
    "        tokens = [re_punc.sub('', token) for token in tokens] \n",
    "        # only include tokens that aren't numbers\n",
    "        tokens = [token for token in tokens if token.isalpha()]\n",
    "        all_tokens.append(tokens)\n",
    "    return all_tokens\n",
    "\n",
    "def read_files(datapath):\n",
    "    '''\n",
    "    Reads and Returns the \"data\" as list of lists (as shown above)\n",
    "    '''\n",
    "    data = []\n",
    "    all_files = os.listdir(datapath)\n",
    "    for file_name in all_files:\n",
    "        print(\"Processing\", file_name)\n",
    "        with open(os.path.join(datapath, file_name)) as file:\n",
    "            data.append(file.read())\n",
    "            break\n",
    "    return data\n",
    "\n",
    "# Now, we're going to actually read in the files\n",
    "# and split them into tokens\n",
    "raw_data = read_files(datapath)\n",
    "cleaned_data = clean_text(raw_data)\n",
    "# sanity check to check out the beginning and end of our data\n",
    "print(\"Number of files read:\", len(cleaned_data))\n",
    "print(cleaned_data[0][:10])  # beginning of first sentence\n",
    "print(cleaned_data[0][-10:]) # end of first sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Vectors and Word2Vec\n",
    "------\n",
    "We'll use the `gensim` model to train word vectors in python. Use the code below to import the library, then define the size (number of dimensions) that you'd like to have in your vectors.\n",
    "\n",
    "Other parameters that we've included here are:\n",
    "- `sg`: stands for \"skip-gram\" this is a flag about whether to use the skip-gram algorithm (\"1\") or the CBOW algorithm (\"0\"). These are two different algorithms for creating word vectors. They both work well and produce very similar results!\n",
    "- `window`: this defines the size of the distance around a particular word to \"look\" when creating word vectors.\n",
    "- `size`: dimensionality of the output vectors\n",
    "- `min_count`: ignores all tokens with total frequency lower than this number\n",
    "\n",
    "For more parameters, [see the documentation](https://radimrehurek.com/gensim/models/word2vec.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the actual word embedding models\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# The dimension of the word embeddings that we're producing. \n",
    "# This variable will be used throughout the program\n",
    "EMBEDDINGS_SIZE = 100\n",
    "\n",
    "# Training Word2Vec model from Gensim. \n",
    "model = Word2Vec(cleaned_data, \n",
    "                 sg=1,\n",
    "                 window=5, \n",
    "                 size=EMBEDDINGS_SIZE,\n",
    "                 min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out how big our vocabulary is\n",
    "print('Vocab size:', len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving file in txt format, so you don't have to remake it each time\n",
    "model.wv.save_word2vec_format('my_embeddings.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying the model\n",
    "--------\n",
    "\n",
    "There are a few different ways that we can query the resulting model! Here are a few of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing by projecting the word vectors into two-dimensional space\n",
    "\n",
    "# we'll need to import some graphing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "# and the projection method that we'll be using\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# tells jupyter notebooks to display the graphs under the cells that produce them\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is heavily based off of code from\n",
    "# https://www.kaggle.com/jeffd23/visualizing-word-vectors-with-t-sne\n",
    "\n",
    "def tsne_plot(model, focus_word = None, n = 50):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    if focus_word is not None:\n",
    "        tokens.append(model.wv[focus_word])\n",
    "        labels.append(focus_word)\n",
    "        neighbors = model.wv.most_similar(focus_word, topn = n)\n",
    "        for neighbor in neighbors:\n",
    "            tokens.append(model.wv[neighbor[0]])\n",
    "            labels.append(neighbor[0])\n",
    "    else:\n",
    "        for word in model.wv.vocab:\n",
    "            tokens.append(model.wv[word])\n",
    "            labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = [value[0] for value in new_values]\n",
    "    y = [value[1] for value in new_values]\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(model, focus_word=\"friend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also directly query the model to ask for the list of words that are most similar to a specific word or the words that are most similar to a target word (or words).\n",
    "\n",
    "See [this documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#what-can-i-do-with-word-vectors) for more examples of interacting with these word vectors and similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a query to get the items most similar to a given term\n",
    "# documentation:\n",
    "# https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.most_similar.html\n",
    "model.wv.most_similar(\"girl\", topn = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most similar to multiple words\n",
    "model.wv.most_similar(positive = [\"girl\", \"woman\"], topn = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most similar to woman - man\n",
    "model.wv.most_similar(positive = [\"woman\"], negative = [\"man\"], topn = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distance between two vectors\n",
    "distance = model.wv.distance(\"woman\", \"man\")\n",
    "print(distance)\n",
    "distance = model.wv.distance(\"horse\", \"man\")\n",
    "print(distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
